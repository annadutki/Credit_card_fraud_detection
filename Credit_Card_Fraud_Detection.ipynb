{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('input\\creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data['normalizedAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data = data.drop(['Amount'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Class  normalizedAmount  \n",
       "0 -0.189115  0.133558 -0.021053      0          0.244964  \n",
       "1  0.125895 -0.008983  0.014724      0         -0.342475  \n",
       "2 -0.139097 -0.055353 -0.059752      0          1.160686  \n",
       "3 -0.221929  0.062723  0.061458      0          0.140534  \n",
       "4  0.502292  0.219422  0.215153      0         -0.073403  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class  normalizedAmount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0          0.244964  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0         -0.342475  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0          1.160686  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0          0.140534  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0         -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['Time'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, data.columns != 'Class']\n",
    "y = data.iloc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 29)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to transform our dataset into arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create deep neural network to check is our transaction is a fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our model. In order to avoid overfitting, Dropout layer is added in-between. In most cases, RELU activation function is used except for last layer where sigmoid activation function is used because we would like to solve binary problem. We should specify in the model how many columns are expected in the 1st layer which should be the same as the number of columns in our dataset. In our last layer we will have single output node - that is a probability of the transaction being a fraud or safe. In the other layers we might have as many nodes as we consider necessary. When it comes to Dropout layer where we will have 0.5 probability of dropping each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_dim=29, activation='relu'),\n",
    "    Dense(units=24, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=20, activation='relu'),\n",
    "    Dense(units=24, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our model using summary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                504       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,917\n",
      "Trainable params: 1,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call compile method using Adam optimizer and use accuracy to measure our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\annak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "199364/199364 [==============================] - 43s 217us/step - loss: 0.0102 - acc: 0.9979\n",
      "Epoch 2/5\n",
      "199364/199364 [==============================] - 58s 291us/step - loss: 0.0041 - acc: 0.9994\n",
      "Epoch 3/5\n",
      "199364/199364 [==============================] - 59s 296us/step - loss: 0.0040 - acc: 0.9994\n",
      "Epoch 4/5\n",
      "199364/199364 [==============================] - 52s 263us/step - loss: 0.0038 - acc: 0.9994\n",
      "Epoch 5/5\n",
      "199364/199364 [==============================] - 48s 240us/step - loss: 0.0033 - acc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab10d0f348>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=15, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85443/85443 [==============================] - 4s 43us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0041294813792382545, 0.999403110845827]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved 99.94% accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85276    20]\n",
      " [   31   116]]\n"
     ]
    }
   ],
   "source": [
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[85276    20]\n",
      " [   31   116]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cnf_matrix, classes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
